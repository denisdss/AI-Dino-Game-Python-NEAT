[NEAT]

# fitness_criterion: Defines how the fitness of genomes will be evaluated.
# In the case of the Dino game, fitness can be based on the highest score achieved or survival time.
# We use max to select the genome with the best performance, i.e., the one that achieves the highest time or score.
fitness_criterion = max

# fitness_threshold: Defines the fitness threshold to consider a genome as a winner.
# If the Dino reaches a score above this value, the evolution will be considered complete.
# For example, if the value is 1000, NEAT will stop the evolution as soon as the Dino reaches or exceeds this score.
fitness_threshold = 1000

# pop_size: Defines the number of individuals (neural networks) in each generation.
# A higher value can yield better results since more neural networks will compete to find the best strategy.
# However, a very high value requires more computational power. For example, a value of 150 can be balanced, but a value of 1000 can be excessive.
pop_size = 150

# reset_on_extinction: Defines if the population will be reset if all individuals go extinct.
# If all individuals fail to reach a minimum fitness, the population will be reset.
# Otherwise, the population evolves with the remaining individuals.
reset_on_extinction = False

[DefaultStagnation]

# species_fitness_func: Defines how the fitness of each species will be evaluated.
# We use the mean fitness of individuals to determine the species' fitness.
# If a species has no good performance, it will be removed.
species_fitness_func = mean

# max_stagnation: Defines the number of generations without improvement to consider a species as stagnant.
# If a species shows no improvement in performance for a number of generations, it will be eliminated.
# A higher value can give more time for evolution, but a very high value can lead to weak species persisting for many generations.
max_stagnation = 10

# species_elitism: Defines the number of species that will be protected from stagnation.
# High-performing species are protected to ensure they are not eliminated due to stagnation.
species_elitism = 2

[DefaultReproduction]

# elitism: Defines the number of elite individuals (with the best fitness) that will be preserved for the next generation.
# This ensures that the best neural networks of each generation survive to the next.
# If the value is too high, it can limit genetic diversity, but a very low value can quickly lose good solutions.
elitism = 2

# survival_threshold: Defines the percentage of individuals in each species that can reproduce.
# This means that, for example, if the value is 0.5, only 50% of the individuals with the highest fitness will reproduce.
survival_threshold = 0.5

# min_species_size: Defines the minimum number of individuals in each species after reproduction.
# This ensures that no species becomes too small, which could reduce genetic diversity.
min_species_size = 5

[DefaultSpeciesSet]

# compatibility_threshold: Defines the compatibility threshold between genomes to consider them of the same species.
# If two genomes have a genomic distance greater than this value, they will be considered different species.
# A lower value can generate more species, but it can hinder evolution. A higher value can limit the formation of new species.
compatibility_threshold = 3.0

[DefaultGenome]

# activation_default: Defines the default activation function for neurons.
# The sigmoid function limits the outputs to the range between 0 and 1, which can be useful for binary decisions like jump or duck.
# The tanh function can be used if the outputs need to vary between -1 and 1, but it can be more difficult to train in some situations.
activation_default = tanh

# activation_mutate_rate: Defines the mutation rate of the activation function.
# A higher rate can generate more diversity in neural networks, but it can also hinder convergence to a good solution.
activation_mutate_rate = 0.1

# activation_options: Defines the available activation function options.
# Sigmoid is common for neural networks with binary decisions, like jump or duck, while tanh can be useful in more complex problems.
activation_options = sigmoid tanh

# aggregation_default: Defines the default aggregation function for neurons.
# Sum can be useful when we want to sum the outputs of several neurons to make a decision.
# Mean can be useful when we want an average of outputs.
aggregation_default = sum

# aggregation_mutate_rate: Defines the mutation rate of the aggregation function.
# Like activation mutation, a very high value can impair model stability.
aggregation_mutate_rate = 0.1

# aggregation_options: Defines the available aggregation function options.
# Sum and mean are common, but other functions can be useful depending on the problem.
aggregation_options = sum mean

# bias_init_mean: Defines the mean of the distribution to initialize the biases of neurons.
# The initial value of biases can affect how neurons behave in the first generations.
bias_init_mean = 0.0

# bias_init_stdev: Defines the standard deviation of the distribution to initialize the biases of neurons.
# A higher value can result in greater variations in initial behavior, which can help avoid premature convergence.
bias_init_stdev = 1.0

# bias_init_type: Defines the type of distribution to initialize the biases of neurons.
# Uniform creates a uniform distribution, while other options, like normal, can generate different behavior.
bias_init_type = uniform

# bias_max_value: Defines the maximum value for the biases of neurons.
# Limiting the bias helps avoid extreme values that can hinder learning.
bias_max_value = 5.0

# bias_min_value: Defines the minimum value for the biases of neurons.
# Limiting the biases also prevents them from straying too far from reasonable values.
bias_min_value = -5.0

# bias_mutate_power: Defines the strength of mutation in the biases of neurons.
# High values can generate drastic changes in neurons, which can be useful for exploring more solutions.
bias_mutate_power = 0.5

# bias_mutate_rate: Defines the mutation rate of the biases of neurons.
# A higher rate can increase diversity, but it can hinder convergence to an optimal solution.
bias_mutate_rate = 0.2

# bias_replace_rate: Defines the replacement rate of the biases of neurons.
# If a bias is replaced, it takes on a new random value, which can generate unexpected behavior.
bias_replace_rate = 0.1

# compatibility_disjoint_coefficient: Defines the coefficient for genomic distance between disjoint genes.
# This affects how genomes with unmatched genes are evaluated.
compatibility_disjoint_coefficient = 1.0

# compatibility_weight_coefficient: Defines the coefficient for genomic distance between connection weights.
# Affects how the weights of connections between neurons are compared during genomic compatibility evaluation.
compatibility_weight_coefficient = 0.5

# conn_add_prob: Defines the probability of adding a new connection.
# Adding connections can help the neural network learn more complex relationships, but it can also increase complexity.
conn_add_prob = 0.7

# conn_delete_prob: Defines the probability of deleting an existing connection.
# Deleting connections can help simplify the network by removing useless connections.
conn_delete_prob = 0.3

# enabled_default: Defines if connections will be enabled by default.
# If true, connections will be initially activated; otherwise, they will be disabled.
enabled_default = True

# enabled_mutate_rate: Defines the mutation rate for enabling/disabling connections.
# Higher rates increase the chance of mutation in connections, which can generate more diversity but also destabilize learning.
enabled_mutate_rate = 0.05

# feed_forward: Defines if the neural network will be feedforward (without loops).
# The model for the Dino game should be feedforward, as the input should follow a single direction from input to output.
feed_forward = True

# initial_connection: Defines how connections will be initialized.
# Full creates connections between all neurons initially, which can be useful for complex models.
# Full_direct creates directed connections between all neurons, which can be useful for sequential problems.
# Full_nodirect creates connections between all neurons, but without direction, which can be useful for non-sequential problems.
# Sparse creates fewer connections, which can be more efficient for simple models.
# Random creates random connections, which can be useful for exploring different architectures.
# The chosen value depends on the complexity of the problem and the available training time.
initial_connection = full

# node_add_prob: Defines the probability of adding a new neuron.
# Adding neurons can allow the network to learn more complex functions.
node_add_prob = 0.5

# node_delete_prob: Defines the probability of deleting an existing neuron.
# Deleting neurons can simplify the network, but it can also remove important information.
node_delete_prob = 0.2

# num_hidden: Defines the number of hidden neurons in the neural network.
# A higher number of hidden neurons can help the network learn more complex functions, but it can increase training time.
num_hidden = 6

# num_inputs: Defines the number of inputs to the neural network (game information).
# Examples of inputs can be the distance to the obstacle, height of the obstacle, etc.
num_inputs = 6

# num_outputs: Defines the number of outputs of the neural network (Dino actions).
# In the case of the Dino, the outputs can be jump (1) or duck (0).
num_outputs = 2

# response_init_mean: Defines the mean of the distribution to initialize the response multipliers of neurons.
response_init_mean = 1.0

# response_init_stdev: Defines the standard deviation of the distribution to initialize the response multipliers of neurons.
response_init_stdev = 0.5

# response_init_type: Defines the type of distribution to initialize the response multipliers of neurons.
response_init_type = uniform

# response_max_value: Defines the maximum value for the response multipliers of neurons.
response_max_value = 5.0

# response_min_value: Defines the minimum value for the response multipliers of neurons.
response_min_value = -5.0

# response_mutate_power: Defines the strength of mutation in the response multipliers of neurons.
response_mutate_power = 0.5

# response_mutate_rate: Defines the mutation rate of the response multipliers of neurons.
response_mutate_rate = 0.1

# response_replace_rate: Defines the replacement rate of the response multipliers of neurons.
response_replace_rate = 0.1

# single_structural_mutation: Defines if only one structural mutation (add or remove neuron/connection) will be allowed per genome per generation.
single_structural_mutation = True

# structural_mutation_surer: Defines if structural mutation will always be performed.
structural_mutation_surer = False

# weight_init_mean: Defines the mean of the distribution to initialize the weights of connections.
weight_init_mean = 0.0

# weight_init_stdev: Defines the standard deviation of the distribution to initialize the weights of connections.
weight_init_stdev = 1.0

# weight_init_type: Defines the type of distribution to initialize the weights of connections.
weight_init_type = uniform

# weight_max_value: Defines the maximum value for the weights of connections.
weight_max_value = 5.0

# weight_min_value: Defines the minimum value for the weights of connections.
weight_min_value = -5.0

# weight_mutate_power: Defines the strength of mutation in the weights of connections.
weight_mutate_power = 0.5

# weight_mutate_rate: Defines the mutation rate of the weights of connections.
weight_mutate_rate = 0.1

# weight_replace_rate: Defines the replacement rate of the weights of connections.
weight_replace_rate = 0.1
